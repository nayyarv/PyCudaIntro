{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LikelihoodEvaluator():\n",
    "    def __init__(self, Xpoints, numMixtures):\n",
    "        assert(Xpoints.ndim==2)\n",
    "\n",
    "        self.Xpoints = Xpoints\n",
    "        self.numPoints, self.dim = Xpoints.shape\n",
    "        self.numMixtures = numMixtures\n",
    "\n",
    "    def loglikelihood(self, means, diagCovs, weights):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    __call__ = loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleCoreLL(LikelihoodEvaluator):\n",
    "\n",
    "    def __init__(self, Xpoints, numMixtures):\n",
    "        print(\"Single Core Implementation Chosen\")\n",
    "        LikelihoodEvaluator.__init__(self, Xpoints, numMixtures)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Single Core Implementation\"\n",
    "\n",
    "\n",
    "\n",
    "    def loglikelihood(self, means, diagCovs, weights):\n",
    "        numMixtures = self.numMixtures\n",
    "\n",
    "\n",
    "\n",
    "        #update if need be\n",
    "\n",
    "        assert(means.shape == (numMixtures, self.dim))\n",
    "        assert(diagCovs.shape == (numMixtures, self.dim))\n",
    "        assert(len(weights)== numMixtures)\n",
    "\n",
    "\n",
    "        numMixtures = len(weights)\n",
    "\n",
    "        ll = np.zeros(self.numPoints)\n",
    "\n",
    "        constMulti = self.dim / 2.0 * np.log(2 * np.pi)\n",
    "\n",
    "        CovDet = np.zeros(numMixtures)\n",
    "\n",
    "        for i in range(numMixtures):\n",
    "            CovDet[i] = 1.0 / np.sqrt(np.prod(diagCovs[i]))\n",
    "\n",
    "        for i in range(self.numPoints):\n",
    "            for mixes in range(numMixtures):\n",
    "                multiVal = 1\n",
    "\n",
    "                temp = np.dot((self.Xpoints[i] - means[mixes]) / diagCovs[mixes], (self. Xpoints[i] - means[mixes]))\n",
    "                temp *= -0.5\n",
    "                ll[i] += weights[mixes] * np.exp(temp) * CovDet[mixes]\n",
    "\n",
    "            ll[i] = np.log(ll[i]) - constMulti\n",
    "\n",
    "        return np.sum(ll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture.gaussian_mixture import GaussianMixture, _compute_precision_cholesky\n",
    "\n",
    "\n",
    "class ScikitLL(LikelihoodEvaluator):\n",
    "    \"\"\"\n",
    "    Fastest Single Core Version so far!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, Xpoints, numMixtures):\n",
    "        print(\"Scikits Learn Implementation Chosen\")\n",
    "        super().__init__(Xpoints, numMixtures)\n",
    "        self.evaluator = GaussianMixture(numMixtures, 'diag')\n",
    "        self.Xpoints = Xpoints\n",
    "        self.evaluator.fit(Xpoints)\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"SciKit's learn implementation Implementation\"\n",
    "\n",
    "    def loglikelihood(self, means, diagCovs, weights):\n",
    "        self.evaluator.weights_ = weights\n",
    "        self.evaluator.covariances_ = diagCovs\n",
    "        self.evaluator.means_ = means\n",
    "        self.evaluator.precisions_cholesky_ = _compute_precision_cholesky(diagCovs, \"diag\")\n",
    "\n",
    "        return self.numPoints * np.sum(self.evaluator.score(self.Xpoints))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "d = 13\n",
    "K = 8\n",
    "\n",
    "testX = np.random.random((N, d))\n",
    "testMu = np.random.random((K, d))\n",
    "testSigma = np.ones((K, d))\n",
    "testWeights = np.ones(K)/K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Core Implementation Chosen\n",
      "Scikits Learn Implementation Chosen\n"
     ]
    }
   ],
   "source": [
    "sc = SingleCoreLL(testX, K)\n",
    "slearn = ScikitLL(testX, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12956.342354467166"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.loglikelihood(testMu, testSigma, testWeights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-12956.342354467166"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slearn.loglikelihood(testMu, testSigma, testWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikits Learn Implementation Chosen\n",
      "Single Core Implementation Chosen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/varun/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class GMM is deprecated; The class GMM is deprecated in 0.18 and will be  removed in 0.20. Use class GaussianMixture instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/varun/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/varun/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/varun/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/varun/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/varun/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/varun/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/varun/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/varun/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/varun/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/varun/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/varun/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/varun/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/varun/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/varun/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/varun/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6111055000073975\n"
     ]
    }
   ],
   "source": [
    "def setup():\n",
    "    import numpy as np\n",
    "    a = np.random.random((100,1))\n",
    "    sk = scikitLL(a, 4)\n",
    "    sk.evaluator.fit(a)\n",
    "\n",
    "    Sin = SingleCoreLL(a,4)\n",
    "\n",
    "    print(np.sum(sk.evaluator.score(a)))\n",
    "\n",
    "    print(Sin.loglikelihood(sk.evaluator.means_, sk.evaluator.covars_, sk.evaluator.weights_))\n",
    "\n",
    "import timeit\n",
    "setupStr = \"\"\"\n",
    "import numpy as np\n",
    "from __main__ import scikitLL, SingleCoreLL\n",
    "a = np.random.random((100,1))\n",
    "sk = scikitLL(a, 4)\n",
    "sk.evaluator.fit(a)\n",
    "Sin = SingleCoreLL(a,4)\n",
    "\"\"\"\n",
    "actuSK = \"\"\"\n",
    "np.sum(sk.evaluator.score(a))\n",
    "\"\"\"\n",
    "\n",
    "actuSin = \"\"\"\n",
    "Sin.loglikelihood(sk.evaluator.means_, sk.evaluator.covars_, sk.evaluator.weights_)\n",
    "\"\"\"\n",
    "\n",
    "print(timeit.timeit(actuSin, setupStr, number = 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-349609f2285d>, line 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-349609f2285d>\"\u001b[0;36m, line \u001b[0;32m33\u001b[0m\n\u001b[0;31m    print \"numBlocks: {}, numPoints: {}\".format(self.numBlocks, self.numPoints)\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class GPULL(LikelihoodEvaluator):\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"GPU Implementation\"\n",
    "\n",
    "    def __init__(self, Xpoints, numMixtures):\n",
    "        print(\"GPU Implementation Chosen\")\n",
    "        LikelihoodEvaluator.__init__(self, Xpoints, numMixtures)\n",
    "\n",
    "        #Pycuda imports\n",
    "        import pycuda.autoinit\n",
    "        from pycuda import gpuarray\n",
    "        from pycuda.compiler import SourceModule\n",
    "\n",
    "        self.gpuarray = gpuarray\n",
    "\n",
    "        with open(\"KernelV2.cu\") as f:\n",
    "\n",
    "            if self.numPoints >= 1024:\n",
    "                mod = SourceModule(f.read().replace('512', '1024'))\n",
    "                self.numThreads = 1024\n",
    "            else:\n",
    "                mod = SourceModule(f.read())\n",
    "                self.numThreads = 512\n",
    "\n",
    "        if self.numPoints > self.numThreads:\n",
    "            self.numBlocks = self.numPoints / self.numThreads\n",
    "            if self.numPoints % self.numThreads != 0: self.numBlocks += 1\n",
    "        else:\n",
    "            self.numBlocks = 1\n",
    "\n",
    "        print \"numBlocks: {}, numPoints: {}\".format(self.numBlocks, self.numPoints)\n",
    "        #Set the right number of threads and blocks given the datasize\n",
    "        #Using a max of 1024 threads, fix correct blocksize\n",
    "\n",
    "\n",
    "        self.likelihoodKernel = mod.get_function(\"likelihoodKernel\")\n",
    "        self.likelihoodKernel.prepare('PPPPiiiP')\n",
    "\n",
    "        self.Xpoints = self.Xpoints.astype(np.float32)\n",
    "        self.Xpoints = gpuarray.to_gpu_async(self.Xpoints)\n",
    "\n",
    "        self.means_gpu = gpuarray.zeros(shape = (self.numMixtures, self.dim), dtype = np.float32)\n",
    "        self.diagCovs_gpu = gpuarray.zeros(shape = (self.numMixtures, self.dim), dtype = np.float32)\n",
    "        self.weights_gpu = gpuarray.zeros(shape = self.numMixtures, dtype = np.float32)\n",
    "\n",
    "        self.llVal = gpuarray.zeros(shape = self.numBlocks,  dtype=np.float32)\n",
    "\n",
    "        #Allocate Memory for all our computations\n",
    "\n",
    "\n",
    "    def loglikelihood(self, means, diagCovs, weights):\n",
    "\n",
    "\n",
    "        assert(means.shape == (self.numMixtures, self.dim))\n",
    "        assert(diagCovs.shape == (self.numMixtures, self.dim))\n",
    "        assert(len(weights)== self.numMixtures)\n",
    "\n",
    "        if means.dtype != np.float32:\n",
    "            means = means.astype(np.float32)\n",
    "        if diagCovs.dtype != np.float32:\n",
    "            diagCovs = diagCovs.astype(np.float32)\n",
    "        if weights.dtype != np.float32:\n",
    "            weights = weights.astype(np.float32)\n",
    "\n",
    "\n",
    "        #quick sanity checks\n",
    "        self.means_gpu.set_async(means)\n",
    "        self.diagCovs_gpu.set_async(diagCovs)\n",
    "        self.weights_gpu.set(weights)\n",
    "\n",
    "        self.likelihoodKernel.prepared_call((self.numBlocks, 1), (self.numThreads, 1, 1),\n",
    "                                       self.Xpoints.gpudata, self.means_gpu.gpudata, self.diagCovs_gpu.gpudata,\n",
    "                                       self.weights_gpu.gpudata,\n",
    "                                       self.dim, self.numPoints, self.numMixtures,\n",
    "                                       self.llVal.gpudata)\n",
    "\n",
    "        ll = self.gpuarray.sum(self.llVal).get()\n",
    "        return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMMEval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "skmod = GMMEval(8, 'diag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianMixture(covariance_type='diag', init_params='kmeans', max_iter=100,\n",
       "        means_init=None, n_components=8, n_init=1, precisions_init=None,\n",
       "        random_state=None, reg_covar=1e-06, tol=0.001, verbose=0,\n",
       "        verbose_interval=10, warm_start=False, weights_init=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skmod.fit(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 13)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skmod.covariances_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6500099582999345"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skmod.score(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
