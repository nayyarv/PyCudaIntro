%% LyX 2.1.3 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.

\documentclass[english]{beamer}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{amsmath}
\usepackage{listings}


\makeatletter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
 % this default might be overridden by plain title style
 \newcommand\makebeamertitle{\frame{\maketitle}}%
 % (ERT) argument for the TOC
 \AtBeginDocument{%
   \let\origtableofcontents=\tableofcontents
   \def\tableofcontents{\@ifnextchar[{\origtableofcontents}{\gobbletableofcontents}}
   \def\gobbletableofcontents#1{\origtableofcontents}
 }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\usetheme{Rochester}
\usecolortheme{beaver}

\usenavigationsymbolstemplate{}
\setbeamercolor{structure}{fg=darkred}
\setbeamercolor{block body}{bg=gray!10!white}

\makeatother

\usepackage{babel}
\begin{document}
\title{Accelerating your Python Code}
\subtitle{For GMMs with PyCUDA}

\author{Varun Nayyar}


\date{27/07/18}
\makebeamertitle

\begin{frame}[t]\frametitle{Outline}
Me = Math Major + Script Kiddy (Manage Expectations)
 
\begin{block}{What to Expect}
  \begin{itemize}
    \item Some Math
    \item Thinking with CUDA and Basic Syntax
    \item How to use PyCUDA to avoid complicated work
  \end{itemize}

\end{block}

\begin{block}{What NOT to Expect}
  \begin{itemize}
    \item How PyCUDA does it's magic
    \item Intermediate/Advanced CUDA
  \end{itemize}
\end{block}


\end{frame}



\begin{frame}[t]\frametitle{Gaussian Mixture Models d=1, K=2}
    \begin{center}
        \includegraphics[width=10cm]{img/Combined.png}
    \end{center}
K-means+=1
\end{frame}


\begin{frame}[t]\frametitle{Gaussian Mixture Models (GMMs)}
\begin{block}{Density Function}
For $K$ mixtures
\begin{align*}
f(\mathbf{x}|\boldsymbol{\pi},\boldsymbol{\mu},\boldsymbol{\Sigma})= & \sum_{k=1}^{K}\pi_{k}\mathcal{N}(\mathbf{x}|\mu_{k},\Sigma_{k}) 
\end{align*}
\end{block}

\begin{block}{Log Likelihood (thing to compute)}
  \begin{align*}
  l(\mu,\Sigma,\mathbf{x})  = &\sum_{i=1}^{N}\ln\left(\sum_{k=1}^{K}\pi_{k}\mathcal{N}(x_{i}|\mu_{k},\Sigma_{k})\right)\label{eq:LogLikelihood}
  \end{align*}
\end{block}

\end{frame}


\begin{frame}[t]\frametitle{Need for speed}
Some post-hoc realizations
\begin{itemize}
    \item GMM likelihood formula doesn't decompose into a mathematically simple form
    \item However, note that the GMM likelihood has a parallelizable form in that each point of each mixture is independent (CUDA vibes)
\end{itemize}
Computational Numbers
\begin{itemize}
    \item Number of flops are of the order of $O(NKd)$, in my case, $N = 10^6$, $K = 8$, $d = 13$. I.e. $O(10^8)$
    \item I needed to evaluate the likelihood $10^6$ times for a fixed dataset while the parameters were varied. (Markov Chain Monte Carlo)
    \item i.e $10^{14}$ floating point operations per run.
\end{itemize}        
\end{frame}

\begin{frame}[t]\frametitle{First Attempt}

\begin{columns}

  \column{0.5\textwidth}
    \begin{itemize}
      \item Eh, my computer is fast enough
      \item Pure Python (numpy)
      \item <2->Averaged 36 us per datapoint, or 36s for whole dataset
      \item <2->$10^6$ evaluations would take ~1 year
    \end{itemize}


  \column{0.5\textwidth}
    \begin{center}
        \includegraphics[height=6cm]{img/doingitlive.jpg}
    \end{center}

\end{columns}

\end{frame}


\begin{frame}[t]\frametitle{Execution speed per N}
    \begin{center}
        \includegraphics[width=10cm]{img/simpleOnly.png}
    \end{center}
\end{frame}


\begin{frame}[t]\frametitle{Second Attempt}

\begin{columns}

  \column{0.5\textwidth}

    \begin{itemize}
      \item Stand on the shoulders of giants (scikit-learn)
      \item Reverse engineered the likelihood evaluator
      \item <2->72x improvement!
      \item <2->Took 0.5 us per datapoint, or 0.5s for whole dataset
      \item <2->$10^6$ evaluations would take ~5 days!
    \end{itemize}


  \column{0.5\textwidth}
    \begin{center}
        \includegraphics[width=4cm,height=6cm]{img/shoulders.jpg}
    \end{center}
\end{columns}

\end{frame}


\begin{frame}[t]\frametitle{Execution speed per N}
    \begin{center}
        \includegraphics[width=10cm]{img/skandsimple.png}
    \end{center}
\end{frame}


\begin{frame}[t]\frametitle{Aside: Timing Methodology and Testing}
Ran on Ubuntu 18.04 - i3, 8GB RAM, >3 years old
\begin{itemize}
    \item fixed $K=8$ and $d=13$ as per live behaviour. Varied $N$ from $10^2$ to $10^6$ for completeness. $10^6$ is intended data size.
    \item Used \texttt{timeit} module with 100 iterations and report totaltime/$100*N$
\end{itemize}
Testing
\begin{itemize}
    \item Compared my hand written version to sample R implementation using idential input datasets and comparing output.
    \item Used \texttt{pytest} to create random tests to check that random data and parameters matched values.
\end{itemize}
It's good to be rigorous - Math Major

\end{frame}


\begin{frame}[t]\frametitle{CUDA}
  \begin{itemize}
    \item Stood for Compute Unified Device Architecture but no one cared so this was forgotten
    \item CUDA devices have Streaming Multiprocessors (SMs) and each has a number of CUDA cores. CUDA runs threads in batches of 32 called Warps. GTX970 has 13 SMs with 128 CUDA cores each.
    \item in the CUDA paradigm, you need plenty of independent threads to take advantage of the architecture and to minimize memory latency via async scheduling.
    \item Not many guarantees of all threads running exactly in parallel, so code still needs to be thread safe. 
    \item number of threads is magnitudes greater than in standard multicore programming. 
  \end{itemize}

\end{frame}

\begin{frame}[t]\frametitle{Thinking with CUDA (Matrix Multiplication)}

\begin{align*}
\left(\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1n}\\
\\
\vdots &  & \ddots\\
a_{n1} &  &  & a_{nn}
\end{array}\right) &\times \left(\begin{array}{cccc}
b_{11} & b_{12} & \cdots & b_{1n}\\
\\
\vdots &  & \ddots\\
b_{n1} &  &  & b
\end{array}\right)
\end{align*}
  \begin{itemize}
    \item <1->Each element on output matrix requires $n$ multiplications and additions. $n^2$ elements. 
    \item <1->Single Core = $O(n^3)$, though tricks allow for $O(n^{2.81})$
    \item<1> CUDA??
    \item<2-> Theoretical CUDA = $O(n)$
    \item<3-> Create $n^2$ threads. Each takes $O(n)$ time and can be run in parallel

  \end{itemize}

\end{frame}

\begin{frame}[t]\frametitle{Thinking with CUDA (Summing an Array)}

Sum an array $\left(\begin{array}{cccc} a_{1} & a_{2} & \cdots & a_{n}\end{array}\right)$


  \begin{itemize}
    \item<1-> Single Core = $O(n)$
    \item<1> CUDA ??
    \item<2-> theoretical CUDA = $O(lg (n))$
    \item<3-> First pass, have $N/2$ threads add pos $i$ and pos $i+N/2$
    \item<4-> Second pass, have $N/4$ threads add pos $i$ and pos $i+N/4$
    \item<4-> Etcetera..

  \end{itemize}

\end{frame}


\begin{frame}[t]\frametitle{CUDA Architecture}
A grid of blocks of threads.
    \begin{center}
        \includegraphics[width=10cm]{img/cudamodel.png}
    \end{center}
Could be 3d if necessary (We're gonna forget that fact)
\end{frame}

\begin{frame}[t]\frametitle{CUDA Architecture}

  \begin{itemize}
    \item Main function is called a kernel
    \item Each block runs 32 threads at a time (called warps) and shares a limited amount of memory available to all threads. Keep Blocks in multiples of 32 threads.
    \item GTX 970 = 128 cores * 13 SMs = 52 concurrent warps.  Most GPUs have more 32 bit processing power (float32)
    \item Generally, Blocks are completed as quickly as possible 
    \item Threads act asynchronously - when they access data, threads give up resources while waiting for data.
    \item Memory access and data transfers (especially between host and device) have a lot of tricks and patterns to optimize (none of which I'm going to investigate)

  \end{itemize}

\end{frame}


\begin{frame}[t]\frametitle{Some CUDA Syntax (C++)}

  \begin{itemize}
    \item Specify the kernel function with the \texttt{\_\_global\_\_} keyword.
    \item Specify GPU function \texttt{\_\_device\_\_} keyword. (As opposed to CPU function, .cu files can be compiled with \texttt{nvcc})
    \item share memory/data across with \texttt{\_\_shared\_\_} keyword. Only available within block
    \item pause thread execution till all threads have reached same point \texttt{\_\_syncthreads()}. Async-esque
    \item \texttt{int index = blockIdx.x * blockDim.x + threadIdx.x}
    is considered idiomatic cuda for indexing global arrays
    \item \texttt{int stride = blockDim.x * gridDim.x;} is used in situations there are fewer threads than data points.


  \end{itemize}

\end{frame}


\begin{frame}[t]\frametitle{PyCUDA}

  \begin{itemize}
    \item CUDA is complex. C++ is messy. I'm a maths major
    \item The mathematics (parameter variation) needed to be done in Python for quick implementation and easy refinement.
    \item Allows for easier kernel writing since you can avoid mallocs for memory management and use static sized arrays
    \item PyCUDA abstracts a lot of the process away, at the cost of fine tuned optimization
    \item Some investigation needed for example 2 dim numpy arrays were flattened to 1d on the device
    \item fast enough was what I needed.
  \end{itemize}

\end{frame}

\begin{frame}[t]\frametitle{CUDA Results}

\begin{columns}

  \column{0.5\textwidth}

    \begin{itemize}
      \item CUDA Impletation
      \item Minimal optimization
      \item <2->50x improvement over sklearn
      \item <2->Took 0.01 us per datapoint, or 0.01s for whole dataset
      \item <2->$10^6$ evaluations would take ~2.5 hours!
    \end{itemize}


  \column{0.5\textwidth}
    \begin{center}
        \includegraphics[height=6cm]{img/nvidiavert.jpg}
    \end{center}
\end{columns}
\end{frame}


\begin{frame}[t]\frametitle{Execution speed per N}
    \begin{center}
        \includegraphics[width=10cm]{img/allLL.png}
    \end{center}
\end{frame}



\begin{frame}[t]\frametitle{Thanks}
Code available at \url{https://github.com/nayyarv/PyCudaIntro}
\begin{center}
Timing Data (100 iterations)

\begin{tabular}{|c|c|c|c|}
\hline 
$N$ & Simple & Sklearn & GPU\tabularnewline
\hline 
\hline 
100 & 0.35 & 0.02  & 0.12\tabularnewline
\hline 
1000 & 3.45 & 0.05 & 0.02\tabularnewline
\hline 
10000 & 34.22 & 0.37 & 0.02\tabularnewline
\hline 
100000 & 344.93 & 4.6 & 0.13\tabularnewline
\hline 
1000000 & 3474.57 & 53.39 & 1.07\tabularnewline
\hline 
\end{tabular}
\end{center}

CUDA and PyCUDA easily installed via \texttt{apt} on Ubuntu 18.04. 

Project was in Speech Recognition and Bayesian Statistics (MCMC)


\end{frame}

\end{document}

